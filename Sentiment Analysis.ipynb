{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\Users\\Delbert\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>favs</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@NateSilver538 Tesla makes cars with sophistic...</td>\n",
       "      <td>Thu Mar 19 04:16:37 +0000 2020</td>\n",
       "      <td>10478</td>\n",
       "      <td>1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tesla's Musk offers to make ventilators amid s...</td>\n",
       "      <td>Thu Mar 19 08:00:33 +0000 2020</td>\n",
       "      <td>1039</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elon Musk says Tesla is willing to make ventil...</td>\n",
       "      <td>Thu Mar 19 15:15:01 +0000 2020</td>\n",
       "      <td>1015</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @SamanthaTheEA: @elonmusk there is not one ...</td>\n",
       "      <td>Thu Mar 19 19:52:25 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Jennerator211 @Tesla You don’t have to now......</td>\n",
       "      <td>Thu Mar 19 19:52:24 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @NateSilver538 Tesla makes cars with sophistic...   \n",
       "1  Tesla's Musk offers to make ventilators amid s...   \n",
       "2  Elon Musk says Tesla is willing to make ventil...   \n",
       "3  RT @SamanthaTheEA: @elonmusk there is not one ...   \n",
       "4  @Jennerator211 @Tesla You don’t have to now......   \n",
       "\n",
       "                             date   favs  retweet  \n",
       "0  Thu Mar 19 04:16:37 +0000 2020  10478     1890  \n",
       "1  Thu Mar 19 08:00:33 +0000 2020   1039      302  \n",
       "2  Thu Mar 19 15:15:01 +0000 2020   1015      238  \n",
       "3  Thu Mar 19 19:52:25 +0000 2020      0       11  \n",
       "4  Thu Mar 19 19:52:24 +0000 2020      0        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla = pd.read_csv(\"Tesla.csv\")\n",
    "tesla.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>favs</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHY IS DOLLAR DYING?  2008 Fed printed $4.5 Tr...</td>\n",
       "      <td>Tue Apr 07 12:14:18 +0000 2020</td>\n",
       "      <td>6867</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The argument of \"the Bitcoin halving is priced...</td>\n",
       "      <td>Mon Apr 06 12:51:25 +0000 2020</td>\n",
       "      <td>1641</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billionaire and former Facebook exec makes the...</td>\n",
       "      <td>Mon Apr 06 14:27:38 +0000 2020</td>\n",
       "      <td>771</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @SamTheCarpetMan: @Breaking911 Good, perhap...</td>\n",
       "      <td>Wed Apr 08 00:32:16 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@LordoftheTrends @DrBitcoinMD What exactly in ...</td>\n",
       "      <td>Wed Apr 08 00:32:15 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  WHY IS DOLLAR DYING?  2008 Fed printed $4.5 Tr...   \n",
       "1  The argument of \"the Bitcoin halving is priced...   \n",
       "2  Billionaire and former Facebook exec makes the...   \n",
       "3  RT @SamTheCarpetMan: @Breaking911 Good, perhap...   \n",
       "4  @LordoftheTrends @DrBitcoinMD What exactly in ...   \n",
       "\n",
       "                             date  favs  retweet  \n",
       "0  Tue Apr 07 12:14:18 +0000 2020  6867     2030  \n",
       "1  Mon Apr 06 12:51:25 +0000 2020  1641      285  \n",
       "2  Mon Apr 06 14:27:38 +0000 2020   771      249  \n",
       "3  Wed Apr 08 00:32:16 +0000 2020     0        1  \n",
       "4  Wed Apr 08 00:32:15 +0000 2020     0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin = pd.read_csv(\"full bitcoin.csv\")\n",
    "bitcoin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>favs</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHY IS DOLLAR DYING?  2008 Fed printed $4.5 Tr...</td>\n",
       "      <td>Tue Apr 07 12:14:18 +0000 2020</td>\n",
       "      <td>8179</td>\n",
       "      <td>2399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The same people who think bitcoin is 'dead' at...</td>\n",
       "      <td>Tue Apr 07 12:47:24 +0000 2020</td>\n",
       "      <td>2124</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You can now watch my full interview with @theR...</td>\n",
       "      <td>Tue Apr 07 11:56:46 +0000 2020</td>\n",
       "      <td>409</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @krakenfx: *NEW* KRAKEN RELEASES MARCH #BIT...</td>\n",
       "      <td>Wed Apr 08 17:00:41 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @MeltedCrypto: 1,000 $XRP to 1 random #Foll...</td>\n",
       "      <td>Wed Apr 08 17:00:40 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  WHY IS DOLLAR DYING?  2008 Fed printed $4.5 Tr...   \n",
       "1  The same people who think bitcoin is 'dead' at...   \n",
       "2  You can now watch my full interview with @theR...   \n",
       "3  RT @krakenfx: *NEW* KRAKEN RELEASES MARCH #BIT...   \n",
       "4  RT @MeltedCrypto: 1,000 $XRP to 1 random #Foll...   \n",
       "\n",
       "                             date  favs  retweet  \n",
       "0  Tue Apr 07 12:14:18 +0000 2020  8179     2399  \n",
       "1  Tue Apr 07 12:47:24 +0000 2020  2124      177  \n",
       "2  Tue Apr 07 11:56:46 +0000 2020   409       87  \n",
       "3  Wed Apr 08 17:00:41 +0000 2020     0        1  \n",
       "4  Wed Apr 08 17:00:40 +0000 2020     0       22  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin2 = pd.read_csv(\"full bitcoin 2.csv\")\n",
    "bitcoin2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>favs</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regarding the Valorant anticheat always runnin...</td>\n",
       "      <td>Fri Apr 17 16:35:15 +0000 2020</td>\n",
       "      <td>4784</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There’s a fake interview going around on Faceb...</td>\n",
       "      <td>Sat Apr 18 09:46:37 +0000 2020</td>\n",
       "      <td>1484</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weekend Trap? Bitcoin Price Hits $7.3K in Atte...</td>\n",
       "      <td>Sat Apr 18 17:59:21 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @biconnections: 🚨Fast #Bitcoin #Crypto #Giv...</td>\n",
       "      <td>Sat Apr 18 17:59:20 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Paolo62103142: You have your own #website ...</td>\n",
       "      <td>Sat Apr 18 17:59:20 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  regarding the Valorant anticheat always runnin...   \n",
       "1  There’s a fake interview going around on Faceb...   \n",
       "2  Weekend Trap? Bitcoin Price Hits $7.3K in Atte...   \n",
       "3  RT @biconnections: 🚨Fast #Bitcoin #Crypto #Giv...   \n",
       "4  RT @Paolo62103142: You have your own #website ...   \n",
       "\n",
       "                             date  favs  retweet  \n",
       "0  Fri Apr 17 16:35:15 +0000 2020  4784      346  \n",
       "1  Sat Apr 18 09:46:37 +0000 2020  1484      108  \n",
       "2  Sat Apr 18 17:59:21 +0000 2020     0        0  \n",
       "3  Sat Apr 18 17:59:20 +0000 2020     0       38  \n",
       "4  Sat Apr 18 17:59:20 +0000 2020     0        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin3 = pd.read_csv(\"full bitcoin 3.csv\")\n",
    "bitcoin3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3832"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = bitcoin.append(bitcoin2, ignore_index = True)\n",
    "df.drop_duplicates(subset = \"text\", inplace = True)\n",
    "\n",
    "df = df.append(bitcoin3, ignore_index = True)\n",
    "df.drop_duplicates(subset = \"text\", inplace = True)\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Defining function to extract polarity scores\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score[\"compound\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>favs</th>\n",
       "      <th>retweet</th>\n",
       "      <th>vader</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHY IS DOLLAR DYING?  2008 Fed printed $4.5 Tr...</td>\n",
       "      <td>Tue Apr 07 12:14:18 +0000 2020</td>\n",
       "      <td>6867</td>\n",
       "      <td>2030</td>\n",
       "      <td>0.8434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The argument of \"the Bitcoin halving is priced...</td>\n",
       "      <td>Mon Apr 06 12:51:25 +0000 2020</td>\n",
       "      <td>1641</td>\n",
       "      <td>285</td>\n",
       "      <td>-0.4588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Billionaire and former Facebook exec makes the...</td>\n",
       "      <td>Mon Apr 06 14:27:38 +0000 2020</td>\n",
       "      <td>771</td>\n",
       "      <td>249</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @SamTheCarpetMan: @Breaking911 Good, perhap...</td>\n",
       "      <td>Wed Apr 08 00:32:16 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@LordoftheTrends @DrBitcoinMD What exactly in ...</td>\n",
       "      <td>Wed Apr 08 00:32:15 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @EtherSmart_ORG: #Ethersmart keep growing s...</td>\n",
       "      <td>Wed Apr 08 00:32:12 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0.8713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @BTC_Prometheus: #Giveaway $60 BTC\\n\\nOne p...</td>\n",
       "      <td>Wed Apr 08 00:32:11 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>693</td>\n",
       "      <td>0.6908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @BitSler: Hello Guys! How are you! 😎\\n\\n10 ...</td>\n",
       "      <td>Wed Apr 08 00:32:09 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.7716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @Dehkunle: What’s stopping you from investi...</td>\n",
       "      <td>Wed Apr 08 00:32:02 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>-0.1531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @YourCryptoJedi: Use Lolli 🍭to earn bitcoin...</td>\n",
       "      <td>Wed Apr 08 00:32:00 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  WHY IS DOLLAR DYING?  2008 Fed printed $4.5 Tr...   \n",
       "1  The argument of \"the Bitcoin halving is priced...   \n",
       "2  Billionaire and former Facebook exec makes the...   \n",
       "3  RT @SamTheCarpetMan: @Breaking911 Good, perhap...   \n",
       "4  @LordoftheTrends @DrBitcoinMD What exactly in ...   \n",
       "5  RT @EtherSmart_ORG: #Ethersmart keep growing s...   \n",
       "6  RT @BTC_Prometheus: #Giveaway $60 BTC\\n\\nOne p...   \n",
       "7  RT @BitSler: Hello Guys! How are you! 😎\\n\\n10 ...   \n",
       "8  RT @Dehkunle: What’s stopping you from investi...   \n",
       "9  RT @YourCryptoJedi: Use Lolli 🍭to earn bitcoin...   \n",
       "\n",
       "                             date  favs  retweet   vader  \n",
       "0  Tue Apr 07 12:14:18 +0000 2020  6867     2030  0.8434  \n",
       "1  Mon Apr 06 12:51:25 +0000 2020  1641      285 -0.4588  \n",
       "2  Mon Apr 06 14:27:38 +0000 2020   771      249  0.0000  \n",
       "3  Wed Apr 08 00:32:16 +0000 2020     0        1  0.8162  \n",
       "4  Wed Apr 08 00:32:15 +0000 2020     0        0  0.0000  \n",
       "5  Wed Apr 08 00:32:12 +0000 2020     0      125  0.8713  \n",
       "6  Wed Apr 08 00:32:11 +0000 2020     0      693  0.6908  \n",
       "7  Wed Apr 08 00:32:09 +0000 2020     0       41  0.7716  \n",
       "8  Wed Apr 08 00:32:02 +0000 2020     0      104 -0.1531  \n",
       "9  Wed Apr 08 00:32:00 +0000 2020     0        1  0.6588  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"vader\"] = df[\"text\"].apply(sentiment_analyzer_scores)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Sentiment Analysis with Sentiment140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-310c9020eba6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    310\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \"\"\"\n\u001b[1;32m--> 312\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_device_properties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_initialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# will define _get_device_properties and _CudaDeviceProperties\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36minit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0mDoes\u001b[0m \u001b[0mnothing\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \"\"\"\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0m_lazy_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    190\u001b[0m             raise RuntimeError(\n\u001b[0;32m    191\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m--> 192\u001b[1;33m         \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  len\n",
       "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  115\n",
       "1          0  is upset that he can't update his Facebook by ...  111\n",
       "2          0  @Kenichan I dived many times for the ball. Man...   89\n",
       "3          0    my whole body feels itchy and like its on fire    47\n",
       "4          0  @nationwideclass no, it's not behaving at all....  111"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['sentiment','id','date','query_string','user','text']\n",
    "train = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", \n",
    "                    header=None, names=cols,\n",
    "                   encoding = \"latin1\")\n",
    "train = train[[\"sentiment\", \"text\"]]\n",
    "train[\"len\"] = [len(x) for x in train[\"text\"]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing URL\n",
    "train[\"text\"] = [re.sub(\"http.{0,8}[A-Za-z0-9./]+\", '', x) for x in train[\"text\"]]\n",
    "\n",
    "#Removing @ tags\n",
    "train[\"text\"] = [re.sub(r'@[A-Za-z0-9]+','', x) for x in train[\"text\"]]\n",
    "\n",
    "#Removing HTML encoding\n",
    "train[\"text\"] = [re.sub(r'&[A-Za-z0-9]+','', x) for x in train[\"text\"]]\n",
    "\n",
    "#Removing Byte Order Mark\n",
    "train[\"text\"] = [re.sub(r'ï¿½', '?', x) for x in train[\"text\"]]\n",
    "\n",
    "#Removing Hashtags\n",
    "train[\"text\"] = [re.sub(r\"#\", ' ', x) for x in train[\"text\"]]\n",
    "\n",
    "#Removing Numbers\n",
    "train[\"text\"] = [re.sub(r\"[0-9]\", ' ', x) for x in train[\"text\"]]\n",
    "\n",
    "#Removing anything that's not a letter\n",
    "train[\"text\"] = [re.sub(r\"[^a-zA-Z]\", ' ', x) for x in train[\"text\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenize the first sentence:\n",
      "['[CLS]', 'aw', '##w', '##w', 'that', 's', 'a', 'bum', '##mer', 'you', 'should', '##a', 'got', 'david', 'carr', 'of', 'third', 'day', 'to', 'do', 'it', 'd', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "sentences = [\"[CLS] \" + query + \" [SEP]\" for query in train[\"text\"]]\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"Tokenize the first sentence:\")\n",
    "print (tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = max([len(x) for x in tokenized_texts]) \n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input_ids.pkl\", 'wb') as save_file:\n",
    "    pickle.dump(input_ids, save_file, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pickle.load(open(\"input_ids.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train[\"sentiment\"].apply(lambda x: 1 if x == 4 else 0)\n",
    "\n",
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=42, test_size=0.2)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=42, test_size=0.2)\n",
    "                                             \n",
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "train_inputs = torch.tensor(train_inputs).long()\n",
    "validation_inputs = torch.tensor(validation_inputs).long()\n",
    "train_labels = torch.tensor(train_labels.values).long()\n",
    "validation_labels = torch.tensor(validation_labels.values).long()\n",
    "train_masks = torch.tensor(train_masks).long()\n",
    "validation_masks = torch.tensor(validation_masks).long()\n",
    "\n",
    "# Select a batch size for training. \n",
    "batch_size = 32\n",
    "\n",
    "# Create an iterator of our data with torch DataLoader \n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  model = nn.DataParallel(model)\n",
    "else:\n",
    "    print(\"Error\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT fine-tuning parameters\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=2e-5,\n",
    "                     warmup=.1)\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "  \n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "# Number of training epochs \n",
    "epochs = 4\n",
    "\n",
    "# BERT training loop\n",
    "for _ in trange(epochs, desc=\"Epoch\"):  \n",
    "  \n",
    "  ## TRAINING\n",
    "  \n",
    "  # Set our model to training mode\n",
    "  model.train()  \n",
    "  # Tracking variables\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    train_loss_set.append(loss.item())    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "       \n",
    "  ## VALIDATION\n",
    "\n",
    "  # Put model in evaluation mode\n",
    "  model.eval()\n",
    "  # Tracking variables \n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "\n",
    "# plot training performance\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(train_loss_set)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
